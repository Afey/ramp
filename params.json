{"name":"Ramp","tagline":"Rapid Machine Learning Prototyping in Python","body":"Ramp - Rapid Machine Learning Prototyping\r\n=========================================\r\n\r\nRamp is a python library for rapid prototyping of machine learning\r\nsolutions. It's a light-weight [pandas](http://pandas.pydata.org)-based \r\nmachine learning framework pluggable with existing \r\npython machine learning and statistics tools \r\n([scikit-learn](http://scikit-learn.org), [rpy2](http://rpy.sourceforge.net/rpy2.html), etc.).\r\nRamp provides a simple, declarative syntax for\r\nexploring features, algorithms and transformations quickly and\r\nefficiently.\r\n\r\nDocumentation: http://ramp.readthedocs.org\r\n\r\n**Why Ramp?**\r\n\r\n *  **Clean, declarative syntax**\r\n    \r\n *  **Complex feature transformations**\r\n\r\n    Chain and combine features:\r\n```python\r\nNormalize(Log('x'))\r\nInteractions([Log('x1'), (F('x2') + F('x3')) / 2])\r\n```\r\n    Reduce feature dimension:\r\n```python\r\nDimensionReduction([F('x%d'%i) for i in range(100)], decomposer=PCA(n_components=3))\r\n```\r\n    Incorporate residuals or predictions to blend with other models:\r\n```python\r\nResiduals(simple_model_def) + Predictions(complex_model_def)\r\n```\r\n\r\n * **Data context awareness**\r\n\r\n    Any feature that uses the target (\"y\") variable will automatically respect the\r\n    current training and test sets. Similarly, preparation data (a feature's mean and stdev, for example)\r\n    is stored and tracked between data contexts.\r\n\r\n\r\n *  **Composability**\r\n\r\n    All features, estimators, and their fits are composable, pluggable and storable.\r\n\r\n *  **Easy extensibility**\r\n\r\n    Ramp has a simple API, allowing you to plug in estimators from\r\n    scikit-learn, rpy2 and elsewhere, or easily build your own feature\r\n    transformations, metrics, feature selectors, reporters, or estimators.\r\n\r\n\r\n## Quick start\r\n[Getting started with Ramp: Classifying insults](http://www.kenvanharen.com/2012/11/getting-started-with-ramp-detecting.html)\r\n\r\nOr, the quintessential Iris example:\r\n\r\n```python\r\nimport pandas\r\nfrom ramp import *\r\nimport urllib2\r\nimport sklearn\r\nfrom sklearn import decomposition\r\n\r\n\r\n# fetch and clean iris data from UCI\r\ndata = pandas.read_csv(urllib2.urlopen(\r\n    \"http://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"))\r\ndata = data.drop([149]) # bad line\r\ncolumns = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'class']\r\ndata.columns = columns\r\n\r\n\r\n# all features\r\nfeatures = [FillMissing(f, 0) for f in columns[:-1]]\r\n\r\n# features, log transformed features, and interaction terms\r\nexpanded_features = (\r\n    features +\r\n    [Log(F(f) + 1) for f in features] +\r\n    [\r\n        F('sepal_width') ** 2,\r\n        combo.Interactions(features),\r\n    ]\r\n)\r\n\r\n\r\n# Define several models and feature sets to explore,\r\n# run 5 fold cross-validation on each and print the results.\r\n# We define 2 models and 4 feature sets, so this will be\r\n# 4 * 2 = 8 models tested.\r\nshortcuts.cv_factory(\r\n    data=data,\r\n\r\n    target=[AsFactor('class')],\r\n    metrics=[\r\n        [metrics.GeneralizedMCC()],\r\n        ],\r\n    # report feature importance scores from Random Forest\r\n    reporters=[\r\n        [reporters.RFImportance()],\r\n        ],\r\n\r\n    # Try out two algorithms\r\n    model=[\r\n        sklearn.ensemble.RandomForestClassifier(\r\n            n_estimators=20),\r\n        sklearn.linear_model.LogisticRegression(),\r\n        ],\r\n\r\n    # and 4 feature sets\r\n    features=[\r\n        expanded_features,\r\n\r\n        # Feature selection\r\n        [trained.FeatureSelector(\r\n            expanded_features,\r\n            # use random forest's importance to trim\r\n            selectors.RandomForestSelector(classifier=True),\r\n            target=AsFactor('class'), # target to use\r\n            n_keep=5, # keep top 5 features\r\n            )],\r\n\r\n        # Reduce feature dimension (pointless on this dataset)\r\n        [combo.DimensionReduction(expanded_features,\r\n                            decomposer=decomposition.PCA(n_components=4))],\r\n\r\n        # Normalized features\r\n        [Normalize(f) for f in expanded_features],\r\n    ]\r\n)\r\n```\r\n\r\n## Status\r\nRamp is alpha currently, so expect bugs, bug fixes and API changes.\r\n\r\n## Requirements\r\n * Numpy\r\n * Scipy    \r\n * Pandas\r\n * PyTables\r\n * Sci-kit Learn\r\n * gensim\r\n\r\n## Author\r\nKen Van Haren. Email with feedback/questions: kvh@science.io [@squaredloss](http://twitter.com/squaredloss)\r\n\r\n## Contributors\r\n * [John McDonnell](https://github.com/johnmcdonnell)\r\n * [Rob Story](https://github.com/wrobstory)\r\n","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}